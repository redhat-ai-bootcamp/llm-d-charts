apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: {{ .Values.namespace }}
data:
  prometheus.yml: |
    global:
      scrape_interval: 5s
      evaluation_interval: 5s
      external_labels:
        cluster: 'llm-d'
        
    rule_files:
      - "/etc/prometheus/rules/*.yml"
      
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
      
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
        
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
        
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - demo-llm
      scheme: https
      tls_config:
        insecure_skip_verify: true
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?:\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

    # Scrape vLLM pods deployed via KServe InferenceService
    - job_name: 'kserve-vllm-pods'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - demo-llm
      scheme: http
      metrics_path: /metrics
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_serving_kserve_io_inferenceservice]
        action: keep
        regex: .+
      - source_labels: [__address__]
        action: replace
        regex: ([^:]+)(?::\d+)?
        replacement: $1:8000
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod
      - source_labels: [__meta_kubernetes_pod_node_name]
        action: replace
        target_label: node
      - source_labels: [__meta_kubernetes_pod_label_serving_kserve_io_inferenceservice]
        action: replace
        target_label: inferenceservice

    # Scrape vLLM pods by label selector (llm-d.ai/role=both) for llm-d
    - job_name: 'vllm-pods'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - demo-llm
      scheme: https
      tls_config:
        insecure_skip_verify: true
      metrics_path: /metrics
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_llm_d_ai_role]
        action: keep
        regex: both
      - source_labels: [__address__]
        action: replace
        regex: ([^:]+)(?::\d+)?
        replacement: $1:8000
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod
      - source_labels: [__meta_kubernetes_pod_node_name]
        action: replace
        target_label: node

    - job_name: 'llm-d-epp-metrics'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - demo-llm
      scheme: http
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_component]
        action: keep
        regex: 'llminferenceservice-router-scheduler'
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: 'metrics|http-metrics'
      - source_labels: [__address__]
        action: replace
        regex: '([^:]+):.*'
        replacement: '${1}:9090'
        target_label: __address__
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: service
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod

  inference_rules.yml: |
    groups:
    - name: inference.rules
      rules:
      - alert: HighInferenceLatency
        expr: histogram_quantile(0.95, rate(vllm_request_duration_seconds_bucket[5m])) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: High inference latency detected
          description: "95th percentile latency is {{ "{{" }} $value {{ "}}" }}s for {{ "{{" }} $labels.instance {{ "}}" }}"
          
      - alert: LowCacheHitRate
        expr: rate(vllm_cache_hit_total[5m]) / rate(vllm_cache_total[5m]) < 0.3
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Low cache hit rate
          description: "Cache hit rate is {{ "{{" }} $value | humanizePercentage {{ "}}" }} for {{ "{{" }} $labels.instance {{ "}}" }}"
          
      - alert: GPUMemoryHigh
        expr: vllm_gpu_memory_usage_bytes / vllm_gpu_memory_total_bytes > 0.9
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: GPU memory usage is high
          description: "GPU memory usage is {{ "{{" }} $value | humanizePercentage {{ "}}" }} on {{ "{{" }} $labels.instance {{ "}}" }}"
          
      - alert: InferenceQueueLengthHigh
        expr: vllm_queue_length > 20
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: High inference queue length
          description: "Queue length is {{ "{{" }} $value {{ "}}" }} on {{ "{{" }} $labels.instance {{ "}}" }}"
