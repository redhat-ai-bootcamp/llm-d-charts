{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "title": "vLLM Baseline Configuration",
  "properties": {
    "namespace": {
      "type": "string",
      "title": "Namespace",
      "description": "Namespace to deploy vLLM",
      "default": "demo-llm"
    },
    "model": {
      "type": "object",
      "title": "Model Configuration",
      "properties": {
        "name": {
          "type": "string",
          "title": "Model Name",
          "description": "Hugging Face model path (e.g., Qwen/Qwen3-0.6B)",
          "default": "Qwen/Qwen3-0.6B"
        },
        "maxModelLen": {
          "type": "integer",
          "title": "Max Context Length",
          "description": "Maximum model context length in tokens",
          "default": 16000,
          "minimum": 1024,
          "maximum": 131072
        }
      }
    },
    "replicas": {
      "type": "integer",
      "title": "Number of Replicas",
      "description": "Number of vLLM replicas to deploy",
      "default": 4,
      "minimum": 1,
      "maximum": 8
    },
    "resources": {
      "type": "object",
      "title": "Resource Configuration",
      "properties": {
        "requests": {
          "type": "object",
          "properties": {
            "cpu": {
              "type": "string",
              "title": "CPU Request",
              "default": "1"
            },
            "memory": {
              "type": "string",
              "title": "Memory Request",
              "default": "8Gi"
            },
            "gpu": {
              "type": "string",
              "title": "GPU Request",
              "description": "Number of GPUs per replica",
              "default": "1"
            }
          }
        }
      }
    }
  }
}
