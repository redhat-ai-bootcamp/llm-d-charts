apiVersion: v1
kind: ConfigMap
metadata:
  name: llama-stack-config
  namespace: {{ .Values.namespace }}
data:
  run.yaml: |
    version: '2'
    image_name: vllm
    metadata_store:
      type: sqlite
      db_path: /tmp/llama_stack_metadata.db
    apis:
      - inference
    models:
      - metadata: {}
        model_id: {{ .Values.model.id }}
        provider_id: vllm
        provider_model_id: {{ .Values.model.providerModelId }}
        model_type: llm
    providers:
      inference:
        - provider_id: vllm
          provider_type: "remote::vllm"
          config:
            url: {{ include "llamastack.inferenceUrl" . | quote }}
            tls_verify: false
    server:
      port: {{ .Values.llamastack.port }}
